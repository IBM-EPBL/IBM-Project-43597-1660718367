{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880d983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5164c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15064dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77874037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89534d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ee2281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 138 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r\"F:\\dataset\\Digital Naturalist Dataset\\train\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657400ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 138 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=train_datagen.flow_from_directory(r\"F:\\dataset\\Digital Naturalist Dataset\\test\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e40591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bird': 0, 'Flower': 1, 'Mammal': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106ff758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bird': 0, 'Flower': 1, 'Mammal': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a658ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d9bfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786a3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5305abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd02752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=300,kernel_initializer=\"random_uniform\",activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "212caf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=200,kernel_initializer=\"random_uniform\",activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce42050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=3,kernel_initializer=\"random_uniform\",activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fbf6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65126c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9508\\3933243730.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=4,epochs=25,validation_data=x_test,validation_steps=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1459 - accuracy: 0.3491WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 1.1459 - accuracy: 0.3491 - val_loss: 1.0732 - val_accuracy: 0.3116\n",
      "Epoch 2/25\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.0755 - accuracy: 0.3868\n",
      "Epoch 3/25\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 1.0280 - accuracy: 0.4245\n",
      "Epoch 4/25\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.9613 - accuracy: 0.5094\n",
      "Epoch 5/25\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8693 - accuracy: 0.5755\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.7695 - accuracy: 0.6981\n",
      "Epoch 7/25\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.7025 - accuracy: 0.6887\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.7440 - accuracy: 0.6415\n",
      "Epoch 9/25\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.7265 - accuracy: 0.6509\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.7094 - accuracy: 0.6509\n",
      "Epoch 11/25\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.6608 - accuracy: 0.6887\n",
      "Epoch 12/25\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.5799 - accuracy: 0.7734\n",
      "Epoch 13/25\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.5611 - accuracy: 0.7358\n",
      "Epoch 14/25\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.5271 - accuracy: 0.7642\n",
      "Epoch 15/25\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.5505 - accuracy: 0.7547\n",
      "Epoch 16/25\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.5224 - accuracy: 0.7736\n",
      "Epoch 17/25\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.5479 - accuracy: 0.7266\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.4585 - accuracy: 0.8019\n",
      "Epoch 19/25\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.5173 - accuracy: 0.7547\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.4415 - accuracy: 0.8113\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.4858 - accuracy: 0.7642\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.4549 - accuracy: 0.7830\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.4743 - accuracy: 0.7642\n",
      "Epoch 24/25\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.4878 - accuracy: 0.7358\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4955 - accuracy: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x252a624caf0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=4,epochs=25,validation_data=x_test,validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3b943fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flora&fauna.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
